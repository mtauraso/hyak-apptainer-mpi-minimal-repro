In-Container PATH and LD_LIBRARY_PATH
LD_LIBRARY_PATH=/sw/ompi/4.1.1-2/lib:/sw/ucx/1.10.0/lib:/usr/lib64/openmpi/lib/::/.singularity.d/libs:/.singularity.d/libs
PATH=/sw/ompi/4.1.1-2/bin:/sw/ucx/1.10.0/bin:/usr/lib64/openmpi/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
In-Container ldd output for hyak compiled osu_hello
	linux-vdso.so.1 (0x00007ffc81f36000)
	libm.so.6 => /lib64/libm.so.6 (0x00001511c5a5d000)
	libmpi.so.40 => /sw/ompi/4.1.1-2/lib/libmpi.so.40 (0x00001511c5737000)
	libpthread.so.0 => /lib64/libpthread.so.0 (0x00001511c5517000)
	libc.so.6 => /lib64/libc.so.6 (0x00001511c5152000)
	/lib64/ld-linux-x86-64.so.2 (0x00001511c5ddf000)
	libopen-rte.so.40 => /sw/ompi/4.1.1-2/lib/libopen-rte.so.40 (0x00001511c4e9b000)
	libopen-orted-mpir.so => /sw/ompi/4.1.1-2/lib/libopen-orted-mpir.so (0x00001511c4c99000)
	libopen-pal.so.40 => /sw/ompi/4.1.1-2/lib/libopen-pal.so.40 (0x00001511c498f000)
	libdl.so.2 => /lib64/libdl.so.2 (0x00001511c478b000)
	librt.so.1 => /lib64/librt.so.1 (0x00001511c4583000)
	libutil.so.1 => /lib64/libutil.so.1 (0x00001511c437f000)
	libz.so.1 => /lib64/libz.so.1 (0x00001511c4168000)
In-Container ldd output for hyak compiled osu_bcast
	linux-vdso.so.1 (0x00007ffcce1f1000)
	libmpi.so.40 => /sw/ompi/4.1.1-2/lib/libmpi.so.40 (0x000014cfa2faa000)
	libstdc++.so.6 => /lib64/libstdc++.so.6 (0x000014cfa2c15000)
	libm.so.6 => /lib64/libm.so.6 (0x000014cfa2893000)
	libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x000014cfa267b000)
	libpthread.so.0 => /lib64/libpthread.so.0 (0x000014cfa245b000)
	libc.so.6 => /lib64/libc.so.6 (0x000014cfa2096000)
	libopen-rte.so.40 => /sw/ompi/4.1.1-2/lib/libopen-rte.so.40 (0x000014cfa1ddf000)
	libopen-orted-mpir.so => /sw/ompi/4.1.1-2/lib/libopen-orted-mpir.so (0x000014cfa1bdd000)
	libopen-pal.so.40 => /sw/ompi/4.1.1-2/lib/libopen-pal.so.40 (0x000014cfa18d3000)
	libdl.so.2 => /lib64/libdl.so.2 (0x000014cfa16cf000)
	librt.so.1 => /lib64/librt.so.1 (0x000014cfa14c7000)
	libutil.so.1 => /lib64/libutil.so.1 (0x000014cfa12c3000)
	libz.so.1 => /lib64/libz.so.1 (0x000014cfa10ac000)
	/lib64/ld-linux-x86-64.so.2 (0x000014cfa32d0000)
Running Hyak-compiled versions of osu_hello and osu_bcast
Container built: Wed Feb  8 21:12:44 UTC 2023
Output of mpirun -V loaded from /sw/ompi/4.1.1-2/bin :
mpirun (Open MPI) 4.1.1

Report bugs to http://www.open-mpi.org/community/help/
Output of ucx_info -v loaded from /sw/ucx/1.10.0/bin :
# UCT version=1.10.0 revision 20697e5
# configured with: --disable-logging --disable-debug --disable-assertions --disable-params-check --prefix=/sw/ucx/1.10.0 --with-avx --with-cuda=/sw/cuda/11.2.2 --with-verbs=/usr CPPFLAGS=-I/sw/numactl-devel/2.0.12-11/usr/include/ LDFLAGS=-L/sw/numactl-devel/2.0.12-11/usr/lib64
--------------------------------------------------------------------------
The library attempted to open the following supporting CUDA libraries,
but each of them failed.  CUDA-aware support is disabled.
libcuda.so.1: cannot open shared object file: No such file or directory
libcuda.dylib: cannot open shared object file: No such file or directory
/usr/lib64/libcuda.so.1: cannot open shared object file: No such file or directory
/usr/lib64/libcuda.dylib: cannot open shared object file: No such file or directory
If you are not interested in CUDA-aware support, then run with
--mca opal_warn_on_missing_libcuda 0 to suppress this message.  If you are interested
in CUDA-aware support, then try setting LD_LIBRARY_PATH to the location
of libcuda.so.1 to get passed this issue.
--------------------------------------------------------------------------
Container built: Wed Feb  8 21:12:44 UTC 2023
Output of mpirun -V loaded from /sw/ompi/4.1.1-2/bin :
mpirun (Open MPI) 4.1.1

Report bugs to http://www.open-mpi.org/community/help/
Output of ucx_info -v loaded from /sw/ucx/1.10.0/bin :
# UCT version=1.10.0 revision 20697e5
# configured with: --disable-logging --disable-debug --disable-assertions --disable-params-check --prefix=/sw/ucx/1.10.0 --with-avx --with-cuda=/sw/cuda/11.2.2 --with-verbs=/usr CPPFLAGS=-I/sw/numactl-devel/2.0.12-11/usr/include/ LDFLAGS=-L/sw/numactl-devel/2.0.12-11/usr/lib64
--------------------------------------------------------------------------
WARNING: The default btl_vader_single_copy_mechanism CMA is
not available due to different user namespaces.

The vader shared memory BTL will fall back on another single-copy
mechanism if one is available. This may result in lower performance.

  Local host: n3015
--------------------------------------------------------------------------
# OSU MPI Hello World Test v7.0
This is a test with 2 processes
[n3015:40103] 1 more process has sent help message help-mpi-common-cuda.txt / dlopen failed
[n3015:40103] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[n3015:40103] 1 more process has sent help message help-btl-vader.txt / cma-different-user-namespace-warning
Container built: Wed Feb  8 21:12:44 UTC 2023
Container built: Wed Feb  8 21:12:44 UTC 2023
Output of mpirun -V loaded from /sw/ompi/4.1.1-2/bin :
mpirun (Open MPI) 4.1.1

Report bugs to http://www.open-mpi.org/community/help/
Output of mpirun -V loaded from /sw/ompi/4.1.1-2/bin :
Output of ucx_info -v loaded from /sw/ucx/1.10.0/bin :
mpirun (Open MPI) 4.1.1

Report bugs to http://www.open-mpi.org/community/help/
Output of ucx_info -v loaded from /sw/ucx/1.10.0/bin :
# UCT version=1.10.0 revision 20697e5
# configured with: --disable-logging --disable-debug --disable-assertions --disable-params-check --prefix=/sw/ucx/1.10.0 --with-avx --with-cuda=/sw/cuda/11.2.2 --with-verbs=/usr CPPFLAGS=-I/sw/numactl-devel/2.0.12-11/usr/include/ LDFLAGS=-L/sw/numactl-devel/2.0.12-11/usr/lib64
# UCT version=1.10.0 revision 20697e5
# configured with: --disable-logging --disable-debug --disable-assertions --disable-params-check --prefix=/sw/ucx/1.10.0 --with-avx --with-cuda=/sw/cuda/11.2.2 --with-verbs=/usr CPPFLAGS=-I/sw/numactl-devel/2.0.12-11/usr/include/ LDFLAGS=-L/sw/numactl-devel/2.0.12-11/usr/lib64
--------------------------------------------------------------------------
The library attempted to open the following supporting CUDA libraries,
but each of them failed.  CUDA-aware support is disabled.
libcuda.so.1: cannot open shared object file: No such file or directory
libcuda.dylib: cannot open shared object file: No such file or directory
/usr/lib64/libcuda.so.1: cannot open shared object file: No such file or directory
/usr/lib64/libcuda.dylib: cannot open shared object file: No such file or directory
If you are not interested in CUDA-aware support, then run with
--mca opal_warn_on_missing_libcuda 0 to suppress this message.  If you are interested
in CUDA-aware support, then try setting LD_LIBRARY_PATH to the location
of libcuda.so.1 to get passed this issue.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
WARNING: The default btl_vader_single_copy_mechanism CMA is
not available due to different user namespaces.

The vader shared memory BTL will fall back on another single-copy
mechanism if one is available. This may result in lower performance.

  Local host: n3015
--------------------------------------------------------------------------

# OSU MPI Broadcast Latency Test v7.0
# Size       Avg Latency(us)
1                       0.79
2                       0.75
4                       0.77
8                       0.76
16                      0.76
32                      0.75
64                      0.81
128                     0.90
256                     0.90
512                     1.06
1024                    1.15
2048                    1.36
4096                    3.55
8192                    5.17
16384                   8.29
32768                  13.73
65536                  20.57
131072                 33.96
262144                 61.80
524288                117.17
1048576               233.01
[n3015:41407] 1 more process has sent help message help-mpi-common-cuda.txt / dlopen failed
[n3015:41407] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[n3015:41407] 1 more process has sent help message help-btl-vader.txt / cma-different-user-namespace-warning
In-Container ldd output for Rocky compiled osu_hello
	linux-vdso.so.1 (0x00007ffe9b7ea000)
	libm.so.6 => /lib64/libm.so.6 (0x000014cdd131a000)
	libmpi.so.40 => /sw/ompi/4.1.1-2/lib/libmpi.so.40 (0x000014cdd0ff4000)
	libpthread.so.0 => /lib64/libpthread.so.0 (0x000014cdd0dd4000)
	libc.so.6 => /lib64/libc.so.6 (0x000014cdd0a0f000)
	/lib64/ld-linux-x86-64.so.2 (0x000014cdd189f000)
	libopen-rte.so.40 => /sw/ompi/4.1.1-2/lib/libopen-rte.so.40 (0x000014cdd0758000)
	libopen-orted-mpir.so => /sw/ompi/4.1.1-2/lib/libopen-orted-mpir.so (0x000014cdd0556000)
	libopen-pal.so.40 => /sw/ompi/4.1.1-2/lib/libopen-pal.so.40 (0x000014cdd024c000)
	libdl.so.2 => /lib64/libdl.so.2 (0x000014cdd0048000)
	librt.so.1 => /lib64/librt.so.1 (0x000014cdcfe40000)
	libutil.so.1 => /lib64/libutil.so.1 (0x000014cdcfc3c000)
	libz.so.1 => /lib64/libz.so.1 (0x000014cdcfa25000)
In-Container ldd output for Rocky compiled osu_bcast
	linux-vdso.so.1 (0x00007ffc0f7e8000)
	libmpi_cxx.so.40 => /usr/lib64/openmpi/lib/libmpi_cxx.so.40 (0x000015013b39d000)
	libmpi.so.40 => /sw/ompi/4.1.1-2/lib/libmpi.so.40 (0x000015013b077000)
	libstdc++.so.6 => /lib64/libstdc++.so.6 (0x000015013ace2000)
	libm.so.6 => /lib64/libm.so.6 (0x000015013a960000)
	libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x000015013a748000)
	libpthread.so.0 => /lib64/libpthread.so.0 (0x000015013a528000)
	libc.so.6 => /lib64/libc.so.6 (0x000015013a163000)
	libopen-rte.so.40 => /usr/lib64/openmpi/lib/libopen-rte.so.40 (0x0000150139ea8000)
	libopen-orted-mpir.so => /usr/lib64/openmpi/lib/libopen-orted-mpir.so (0x0000150139ca6000)
	libopen-pal.so.40 => /usr/lib64/openmpi/lib/libopen-pal.so.40 (0x00001501399f8000)
	libdl.so.2 => /lib64/libdl.so.2 (0x00001501397f4000)
	librt.so.1 => /lib64/librt.so.1 (0x00001501395ec000)
	libutil.so.1 => /lib64/libutil.so.1 (0x00001501393e8000)
	libz.so.1 => /lib64/libz.so.1 (0x00001501391d1000)
	libhwloc.so.15 => /lib64/libhwloc.so.15 (0x0000150138f81000)
	libevent_core-2.1.so.6 => /lib64/libevent_core-2.1.so.6 (0x0000150138d48000)
	libevent_pthreads-2.1.so.6 => /lib64/libevent_pthreads-2.1.so.6 (0x0000150138b45000)
	/lib64/ld-linux-x86-64.so.2 (0x000015013b7d2000)
	libcrypto.so.1.1 => /lib64/libcrypto.so.1.1 (0x000015013865c000)
Running Rocky-compiled versions of osu_hello and osu_bcast
Container built: Wed Feb  8 21:12:44 UTC 2023
Container built: Wed Feb  8 21:12:44 UTC 2023
Output of mpirun -V loaded from /sw/ompi/4.1.1-2/bin :
mpirun (Open MPI) 4.1.1

Report bugs to http://www.open-mpi.org/community/help/
Output of ucx_info -v loaded from /sw/ucx/1.10.0/bin :
Output of mpirun -V loaded from /sw/ompi/4.1.1-2/bin :
mpirun (Open MPI) 4.1.1

Report bugs to http://www.open-mpi.org/community/help/
# UCT version=1.10.0 revision 20697e5
# configured with: --disable-logging --disable-debug --disable-assertions --disable-params-check --prefix=/sw/ucx/1.10.0 --with-avx --with-cuda=/sw/cuda/11.2.2 --with-verbs=/usr CPPFLAGS=-I/sw/numactl-devel/2.0.12-11/usr/include/ LDFLAGS=-L/sw/numactl-devel/2.0.12-11/usr/lib64
Output of ucx_info -v loaded from /sw/ucx/1.10.0/bin :
# UCT version=1.10.0 revision 20697e5
# configured with: --disable-logging --disable-debug --disable-assertions --disable-params-check --prefix=/sw/ucx/1.10.0 --with-avx --with-cuda=/sw/cuda/11.2.2 --with-verbs=/usr CPPFLAGS=-I/sw/numactl-devel/2.0.12-11/usr/include/ LDFLAGS=-L/sw/numactl-devel/2.0.12-11/usr/lib64
--------------------------------------------------------------------------
The library attempted to open the following supporting CUDA libraries,
but each of them failed.  CUDA-aware support is disabled.
libcuda.so.1: cannot open shared object file: No such file or directory
libcuda.dylib: cannot open shared object file: No such file or directory
/usr/lib64/libcuda.so.1: cannot open shared object file: No such file or directory
/usr/lib64/libcuda.dylib: cannot open shared object file: No such file or directory
If you are not interested in CUDA-aware support, then run with
--mca opal_warn_on_missing_libcuda 0 to suppress this message.  If you are interested
in CUDA-aware support, then try setting LD_LIBRARY_PATH to the location
of libcuda.so.1 to get passed this issue.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
WARNING: The default btl_vader_single_copy_mechanism CMA is
not available due to different user namespaces.

The vader shared memory BTL will fall back on another single-copy
mechanism if one is available. This may result in lower performance.

  Local host: n3015
--------------------------------------------------------------------------
# OSU MPI Hello World Test v5.7.1
This is a test with 2 processes
[n3015:47810] 1 more process has sent help message help-mpi-common-cuda.txt / dlopen failed
[n3015:47810] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[n3015:47810] 1 more process has sent help message help-btl-vader.txt / cma-different-user-namespace-warning
Container built: Wed Feb  8 21:12:44 UTC 2023
Container built: Wed Feb  8 21:12:44 UTC 2023
Output of mpirun -V loaded from /sw/ompi/4.1.1-2/bin :
mpirun (Open MPI) 4.1.1

Report bugs to http://www.open-mpi.org/community/help/
Output of mpirun -V loaded from /sw/ompi/4.1.1-2/bin :
Output of ucx_info -v loaded from /sw/ucx/1.10.0/bin :
mpirun (Open MPI) 4.1.1

Report bugs to http://www.open-mpi.org/community/help/
Output of ucx_info -v loaded from /sw/ucx/1.10.0/bin :
# UCT version=1.10.0 revision 20697e5
# configured with: --disable-logging --disable-debug --disable-assertions --disable-params-check --prefix=/sw/ucx/1.10.0 --with-avx --with-cuda=/sw/cuda/11.2.2 --with-verbs=/usr CPPFLAGS=-I/sw/numactl-devel/2.0.12-11/usr/include/ LDFLAGS=-L/sw/numactl-devel/2.0.12-11/usr/lib64
# UCT version=1.10.0 revision 20697e5
# configured with: --disable-logging --disable-debug --disable-assertions --disable-params-check --prefix=/sw/ucx/1.10.0 --with-avx --with-cuda=/sw/cuda/11.2.2 --with-verbs=/usr CPPFLAGS=-I/sw/numactl-devel/2.0.12-11/usr/include/ LDFLAGS=-L/sw/numactl-devel/2.0.12-11/usr/lib64
mpitests-osu_bcast: symbol lookup error: /sw/ompi/4.1.1-2/lib/libmca_common_dstore.so.1: undefined symbol: pmix_output_check_verbosity
mpitests-osu_bcast: symbol lookup error: /sw/ompi/4.1.1-2/lib/libmca_common_dstore.so.1: undefined symbol: pmix_output_check_verbosity
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[61539,1],1]
  Exit code:    127
--------------------------------------------------------------------------
